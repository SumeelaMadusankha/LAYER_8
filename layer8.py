# -*- coding: utf-8 -*-
"""LAYER8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_CZKP79fyq9lqtfEaboyB78EaV1evYd
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
from sklearn.decomposition import PCA
#grid search
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score

# Load the data
train_data = pd.read_csv('train.csv')
valid_data = pd.read_csv('valid.csv')
test_data = pd.read_csv('test.csv')

# Split data into features (X) and target labels (y)
X_train = train_data.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_label_1_train = train_data['label_1']
y_label_2_train = train_data['label_2']
y_label_3_train = train_data['label_3']
y_label_4_train = train_data['label_4']

X_valid = valid_data.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_valid_label1 = valid_data['label_1']
y_valid_label2 = valid_data['label_2']
y_valid_label3 = valid_data['label_3']
y_valid_label4 = valid_data['label_4']

X_test = test_data.drop(['ID'], axis=1)

output = pd.DataFrame(index=range(744))
output['ID'] = test_data['ID']

validate = pd.DataFrame()

# count individual unique count of each label category
class_distribution =train_data['label_4'].value_counts()
print(class_distribution)

"""# Apply feature engineering techniques"""

sc = RobustScaler()

X_train_scaled = sc.fit_transform(X_train)
X_valid_scaled = sc.transform(X_valid)
X_test_scaled = sc.transform(X_test)

# Calculate the variance threshold
desired_variance = 0.97  # Set the desired explained variance
pca = PCA(n_components=desired_variance, svd_solver='full')
X_train_pca = pca.fit_transform(X_train_scaled)
X_valid_pca =pca.transform(X_valid_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Get the number of components selected based on the variance threshold
n_components = pca.n_components_

"""# Cross validation for label 1"""

cv_score = cross_val_score(SVC(random_state=42, kernel='linear', gamma='auto'), X_train_pca, y_label_1_train, cv=5)

print(f"Cross-validation accuracy for svc label_1: {np.mean(cv_score):.2f}")

cv_score = cross_val_score(KNN(n_neighbors=5), X_train_pca, y_label_1_train, cv=5)

print(f"Cross-validation accuracy for knn_label_1: {np.mean(cv_score):.2f}")

"""# Grid search for label 1"""

#grid searchcv
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'gamma': ['auto', 'scale']}
kernal = ['linear', 'poly', 'rbf', 'sigmoid']
gamma = ['auto', 'scale']

gs_ = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs = SVC(C=0.1, gamma='auto', kernel='linear')
gs = gs.fit(X_train_pca, y_label_1_train)


#evaluate train model
pred_label_1 = gs.predict(X_valid_pca)
print(len(pred_label_1))
#save on to csv file
validate['LABEL1']=pred_label_1


#save on to csv file
validate.to_csv('validate.csv', index=False)


print('Validate accuracy: %.3f' % accuracy_score(y_true=y_valid_label1, y_pred=pred_label_1))
print('Validate precision: %.3f' % precision_score(y_true=y_valid_label1, y_pred=pred_label_1, average='micro'))
print('Validate recall: %.3f' % recall_score(y_true=y_valid_label1, y_pred=pred_label_1,    average='micro'))
print('Validate f1: %.3f' % f1_score(y_true=y_valid_label1, y_pred=pred_label_1,    average='micro'))

"""# Cross validation for label 2

"""

train_data_label_2 = train_data[train_data['label_2'].notna()]
X_train_label_2 = train_data_label_2.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_label2_train = train_data_label_2['label_2']

X_train_label2_scaled = sc.fit_transform(X_train_label_2)

valid_data_label_2 = valid_data[valid_data['label_2'].notna()]
X_valid_label_2 = valid_data_label_2.drop(['label_1', 'label_2', 'label_3', 'label_4'], axis=1)
y_valid_label_2 = valid_data_label_2['label_2']

X_test_label_2 = test_data.drop(['ID'], axis=1)

X_valid_label2_scaled = sc.transform(X_valid_label_2)
X_test_label_2_scaled = sc.transform(X_test_label_2)


# Calculate the variance threshold
desired_variance = 0.97  # Set the desired explained variance
pca_label2 = PCA(n_components=desired_variance, svd_solver='full')
X_train_label2_pca = pca_label2.fit_transform(X_train_label2_scaled)
X_valid_label2_pca =pca_label2.transform(X_valid_label2_scaled)
X_test_label2_pca = pca_label2.transform(X_test_label_2_scaled)


# Get the number of components selected based on the variance threshold
n_components_label2 = pca.n_components_

print(X_train_label2_pca.shape)
print(y_label2_train.shape)

cv_score = cross_val_score(KNN(n_neighbors=5), X_train_label2_pca, y_label2_train, cv=5)
print(f"Cross-validation accuracy for knn_label_2: {np.mean(cv_score):.2f}")

cv_score = cross_val_score(SVC(random_state=42, kernel='linear', gamma='auto'), X_train_label2_pca, y_label2_train, cv=5)
print(f"Cross-validation accuracy for svc_label_2: {np.mean(cv_score):.2f}")

"""# Grid search for label 2"""

#grid searchcv for knn
param_grid = {
    'n_neighbors': np.arange(1, 25),
     'weights': ['uniform', 'distance'],
    'p': [1, 2]  # Corresponds to Manhattan and Euclidean distances
              }
# gs_label_2_ = GridSearchCV(estimator=KNN(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs_label_2 = KNN(n_neighbors=5, weights='uniform', p=1)
gs_label_2 = gs_label_2.fit(X_train_label2_pca, y_label2_train)


#evaluate train model
pred_label_2 = gs_label_2.predict(X_valid_label2_pca)
validate1 = pd.DataFrame()
validate1['LABEL2']=pred_label_2
validate1.to_csv('validate1.csv', index=False)
print('Validate accuracy: %.3f' % accuracy_score(y_true=y_valid_label_2, y_pred=pred_label_2))
print('Validate precision: %.3f' % precision_score(y_true=y_valid_label_2, y_pred=pred_label_2, average='micro'))
print('Validate recall: %.3f' % recall_score(y_true=y_valid_label_2, y_pred=pred_label_2,    average='micro'))
print('Validate f1: %.3f' % f1_score(y_true=y_valid_label_2, y_pred=pred_label_2,    average='micro'))

#svc grid searchcv
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'gamma': ['auto', 'scale']}
gs_label_2_svc = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs_label_2_svc = gs_label_2_svc.fit(X_train_label2_pca, y_label2_train)
print(gs_label_2_svc.best_score_)
print(gs_label_2_svc.best_params_)
print(gs_label_2_svc.best_params_['C'])
print(gs_label_2_svc.best_params_['kernel'])
print(gs_label_2_svc.best_params_['gamma'])
#evaluate train model
pred_label_2_svc = gs_label_2_svc.predict(X_valid_label2_pca)
print('Validate accuracy: %.3f' % accuracy_score(y_true=y_valid_label_2, y_pred=pred_label_2_svc))
print('Validate precision: %.3f' % precision_score(y_true=y_valid_label_2, y_pred=pred_label_2_svc, average='micro'))
print('Validate recall: %.3f' % recall_score(y_true=y_valid_label_2, y_pred=pred_label_2_svc,    average='micro'))
print('Validate f1: %.3f' % f1_score(y_true=y_valid_label_2, y_pred=pred_label_2_svc,    average='micro'))

"""# Cross validation for label 3"""

cv_score = cross_val_score(KNN(n_neighbors=5), X_train_pca, y_label_3_train, cv=5)
print(f"Cross-validation accuracy for knn_label_3: {np.mean(cv_score):.2f}")

cv_score = cross_val_score(SVC(random_state=42, kernel='linear', gamma='auto'), X_train_pca, y_label_3_train, cv=5)
print(f"Cross-validation accuracy for svc_label_3: {np.mean(cv_score):.2f}")

"""# Grid search for label 3"""

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'gamma': ['auto', 'scale']}
gs_label_3_svc_ = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs_label_3_svc = SVC(C=0.1, gamma='auto', kernel='linear')
gs_label_3_svc = gs_label_3_svc.fit(X_train_pca, y_label_3_train)


#evaluate train model
pred_label_3_svc = gs_label_3_svc.predict(X_valid_pca)
validate3 = pd.DataFrame()

validate3['LABEL3']=pred_label_3_svc
validate3.to_csv('validate3.csv', index=False)
print('Validate accuracy for label 3: %.3f' % accuracy_score(y_true=y_valid_label3, y_pred=pred_label_3_svc))
print('Validate precision for label 3: %.3f' % precision_score(y_true=y_valid_label3, y_pred=pred_label_3_svc, average='micro'))
print('Validate recall for label 3: %.3f' % recall_score(y_true=y_valid_label3, y_pred=pred_label_3_svc,    average='micro'))
print('Validate f1 for label 3: %.3f' % f1_score(y_true=y_valid_label3, y_pred=pred_label_3_svc,    average='micro'))

"""# Cross validation for label 4"""

cv_score = cross_val_score(KNN(n_neighbors=5), X_train_pca, y_label_4_train, cv=5)
print(f"Cross-validation accuracy for knn_label_4: {np.mean(cv_score):.2f}")

cv_score = cross_val_score(SVC(random_state=42, kernel='linear', gamma='auto'), X_train_pca, y_label_4_train, cv=5)
print(f"Cross-validation accuracy for svc_label_4: {np.mean(cv_score):.2f}")

"""# Grid search for label 4"""

# grid searchcv for knn
param_grid = {'n_neighbors': np.arange(1, 25),
                'weights': ['uniform', 'distance'],
              'p': [1, 2]    }
gs_label_4 = GridSearchCV(estimator=KNN(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs_label_4 = gs_label_4.fit(X_train_pca, y_label_4_train)
print(gs_label_4.best_score_)
print(gs_label_4.best_params_)
#evaluate train model
pred_label_4 = gs_label_4.predict(X_valid_pca)
print('Validate accuracy for label 4: %.3f' % accuracy_score(y_true=y_valid_label4, y_pred=pred_label_4))
print('Validate precision for label 4: %.3f' % precision_score(y_true=y_valid_label4, y_pred=pred_label_4, average='micro'))
print('Validate recall for label 4: %.3f' % recall_score(y_true=y_valid_label4, y_pred=pred_label_4,    average='micro'))
print('Validate f1 for label 4: %.3f' % f1_score(y_true=y_valid_label4, y_pred=pred_label_4,    average='micro'))

# grid searchcv for svc
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'gamma': ['auto', 'scale']}
gs_label_4_svc_ = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)
gs_label_4_svc = SVC(C=0.01, gamma='auto', kernel='linear')
gs_label_4_svc = gs_label_4_svc.fit(X_train_pca, y_label_4_train)

#evaluate train model
pred_label_4_svc = gs_label_4_svc.predict(X_valid_pca)
validate4 = pd.DataFrame()
validate4['LABEL4']=pred_label_4_svc
validate4.to_csv('validate4.csv', index=False)
print('Validate accuracy for label 4: %.3f' % accuracy_score(y_true=y_valid_label4, y_pred=pred_label_4_svc))
print('Validate precision for label 4: %.3f' % precision_score(y_true=y_valid_label4, y_pred=pred_label_4_svc, average='micro'))
print('Validate recall for label 4: %.3f' % recall_score(y_true=y_valid_label4, y_pred=pred_label_4_svc,    average='micro'))
print('Validate f1 for label 4: %.3f' % f1_score(y_true=y_valid_label4, y_pred=pred_label_4_svc,    average='micro'))

#save on to csv file
validate.to_csv('validate.csv', index=False)

print(X_test.describe())

pred_test_label1= gs.predict(X_test_pca)
pred_test_label2= gs_label_2.predict(X_test_label2_pca)
pred_test_label3= gs_label_3_svc.predict(X_test_pca)
pred_test_label4= gs_label_4_svc.predict(X_test_pca)

output['label_1'] = pred_test_label1
output['label_2'] = pred_test_label2
output['label_3'] = pred_test_label3
output['label_4'] = pred_test_label4

output.to_csv('label.csv', index=False)